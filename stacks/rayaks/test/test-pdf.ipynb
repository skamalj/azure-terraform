{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74591e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ALTERNATIVE: Simplified client without olmocr toolkit (less accurate)\n",
    "# This approach doesn't use document anchoring but still works for basic OCR\n",
    "\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import pdf2image\n",
    "import io\n",
    "import json\n",
    "\n",
    "def simple_pdf_to_olmocr(pdf_path, page_num=1):\n",
    "    \"\"\"\n",
    "    Simple PDF to OLMoCR without document anchoring\n",
    "    Note: This is less accurate than the full approach above\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert PDF page to image\n",
    "    pages = pdf2image.convert_from_path(pdf_path, first_page=page_num, last_page=page_num)\n",
    "    if not pages:\n",
    "        raise ValueError(\"Could not convert PDF page to image\")\n",
    "\n",
    "    # Resize image to 1024px longest dimension\n",
    "    image = pages[0]\n",
    "    max_dim = max(image.size)\n",
    "    if max_dim > 1024:\n",
    "        scale = 1024 / max_dim\n",
    "        new_size = (int(image.size[0] * scale), int(image.size[1] * scale))\n",
    "        image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Convert to base64\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format='PNG')\n",
    "    image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "    # Simple prompt (not as good as document anchoring)\n",
    "    prompt = \"\"\"\n",
    "You are an intelligent data extraction assistant. \n",
    "You are given the first page of a bank statement that contains both account information and transaction table headers.\n",
    "\n",
    "Your goal:\n",
    "1. Identify and extract all account metadata fields (top section).\n",
    "2. Identify the column headers used for the transaction table on this page.\n",
    "\n",
    "Return a JSON object in this format:\n",
    "\n",
    "{\n",
    "  \"account_info_fields\": [\n",
    "    \"Account Name\",\n",
    "    \"Account Number\",\n",
    "    \"Branch\",\n",
    "    \"IFS Code\",\n",
    "    \"MICR Code\",\n",
    "    \"Account Type\",\n",
    "    \"Balance as on\",\n",
    "    \"Period From\",\n",
    "    \"Period To\",\n",
    "    ...\n",
    "  ],\n",
    "  \"transaction_columns\": [\n",
    "    \"Date\",\n",
    "    \"Details\",\n",
    "    \"Ref No./Cheque No\",\n",
    "    \"Debit\",\n",
    "    \"Credit\",\n",
    "    \"Balance\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Capture **only visible text**. \n",
    "- Preserve original capitalization and punctuation.\n",
    "- If some labels are repeated or similar (e.g., ‚ÄúRef No.‚Äù and ‚ÄúRef No./Cheque No‚Äù), keep only the most complete one.\n",
    "- Do not extract actual data values in this step ‚Äî only the labels/headers.\n",
    "- Always return valid JSON.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Send to vLLM\n",
    "    client = OpenAI(api_key=\"EMPTY\", base_url=\"http://localhost:8000/v1\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"InternVL3_5\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"}}\n",
    "            ]\n",
    "        }],\n",
    "        max_tokens=4096,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Usage\n",
    "result = simple_pdf_to_olmocr(\"sbi.pdf\", 1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494792b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_metadata_prompt(account_info_fields):\n",
    "    field_list = \", \".join([f'\"{f}\"' for f in account_info_fields])\n",
    "    return f\"\"\"\n",
    "You are a precise data extraction assistant.\n",
    "Extract the following account metadata fields from the input text:\n",
    "\n",
    "{field_list}\n",
    "\n",
    "Return JSON strictly in this format:\n",
    "\n",
    "{{\n",
    "  \"account_info\": {{\n",
    "    {\", \".join([f'\"{f}\": \"\"' for f in account_info_fields])}\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Use the exact field names provided above as JSON keys.\n",
    "- If a field is missing, set its value to \"-\".\n",
    "- Only return JSON. No comments or explanations.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121def29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transaction_prompt(transaction_columns):\n",
    "    # Normalize to JSON keys\n",
    "    normalized_keys = [c.lower().replace(\" \", \"_\").replace(\"/\", \"_\").replace(\".\", \"\").replace(\"(\", \"\").replace(\")\", \"\") for c in transaction_columns]\n",
    "    json_fields = \", \".join([f'\"{k}\": \"\"' for k in normalized_keys])\n",
    "    \n",
    "    return f\"\"\"\n",
    "You are a structured data extraction assistant.\n",
    "\n",
    "You are given one page of a bank statement and must extract transaction data using the following columns:\n",
    "{transaction_columns}\n",
    "\n",
    "Return valid JSON strictly in this format:\n",
    "\n",
    "{{\n",
    "  \"transactions\": [\n",
    "    {{\n",
    "      {json_fields}\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Map each extracted value to the appropriate column from the list above.\n",
    "- Keep the exact text for details and reference numbers.\n",
    "- If a field is not found, use \"-\".\n",
    "- Keep two decimal places for numeric values.\n",
    "- Do not include extra commentary or text outside of JSON.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845fa6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import pdf2image\n",
    "\n",
    "# ---- CONFIG ----\n",
    "API_BASE = \"http://localhost:8000/v1\"\n",
    "MODEL_NAME = \"olmOCR-7B-0225-preview\"\n",
    "MAX_IMG_DIM = 1024\n",
    "\n",
    "client = OpenAI(api_key=\"EMPTY\", base_url=API_BASE)\n",
    "\n",
    "# ---- UTILITIES ----\n",
    "def pdf_to_images(pdf_path, dpi=200):\n",
    "    \"\"\"Convert all PDF pages to images.\"\"\"\n",
    "    return pdf2image.convert_from_path(pdf_path, dpi=dpi)\n",
    "\n",
    "def image_to_base64(image: Image.Image):\n",
    "    \"\"\"Convert PIL Image to base64 PNG.\"\"\"\n",
    "    max_dim = max(image.size)\n",
    "    if max_dim > MAX_IMG_DIM:\n",
    "        scale = MAX_IMG_DIM / max_dim\n",
    "        new_size = (int(image.size[0] * scale), int(image.size[1] * scale))\n",
    "        image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format='PNG')\n",
    "    return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "def call_ocr_llm(prompt, image_base64):\n",
    "    \"\"\"Call OCR-capable LLM with an image and prompt.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"}}\n",
    "            ]\n",
    "        }],\n",
    "        max_tokens=4096,\n",
    "        temperature=0.1,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "# ---- PROMPTS ----\n",
    "def schema_prompt():\n",
    "    return \"\"\"\n",
    "You are an intelligent data extraction assistant.\n",
    "You are given the first page of a bank statement that contains both account information and transaction table headers.\n",
    "\n",
    "Your goal:\n",
    "1. Identify and extract all account metadata fields (top section).\n",
    "2. Identify the column headers used for the transaction table on this page.\n",
    "\n",
    "Return JSON in this format:\n",
    "{\n",
    "  \"account_info_fields\": [\"...\"],\n",
    "  \"transaction_columns\": [\"...\"]\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Extract only visible labels (no values).\n",
    "- Preserve original capitalization.\n",
    "- Prefer complete labels (e.g., ‚ÄúRef No./Cheque No‚Äù over ‚ÄúRef No.‚Äù).\n",
    "- Return valid JSON only.\n",
    "\"\"\"\n",
    "\n",
    "def build_metadata_prompt(account_info_fields):\n",
    "    field_list = \", \".join([f'\"{f}\"' for f in account_info_fields])\n",
    "    json_fields = \", \".join([f'\"{f}\": \"\"' for f in account_info_fields])\n",
    "    return f\"\"\"\n",
    "You are a precise data extraction assistant.\n",
    "Extract the following metadata fields from the image:\n",
    "\n",
    "{field_list}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"account_info\": {{\n",
    "    {json_fields}\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Use exact field names.\n",
    "- If a field is missing, set its value to \"-\".\n",
    "- Return only JSON.\n",
    "\"\"\"\n",
    "\n",
    "def build_transaction_prompt(transaction_columns):\n",
    "    json_fields = \", \".join([f'\"{c}\": \"\"' for c in transaction_columns])\n",
    "    return f\"\"\"\n",
    "You are a structured data extraction assistant.\n",
    "Extract all transactions visible in this page using the following headers:\n",
    "{transaction_columns}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"transactions\": [\n",
    "    {{\n",
    "      {json_fields}\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Map values based on column headers.\n",
    "- Use '-' for missing values.\n",
    "- Keep numeric precision to two decimals.\n",
    "- Do not include commentary or metadata.\n",
    "- Return valid JSON only.\n",
    "\"\"\"\n",
    "\n",
    "# ---- MAIN PIPELINE ----\n",
    "def process_bank_statement(pdf_path):\n",
    "    pages = pdf_to_images(pdf_path)\n",
    "\n",
    "    # Stage 1 ‚Üí Schema Discovery (first page)\n",
    "    first_page_b64 = image_to_base64(pages[0])\n",
    "    schema = call_ocr_llm(schema_prompt(), first_page_b64)\n",
    "\n",
    "    # Stage 2 ‚Üí Metadata Extraction (first page)\n",
    "    metadata_prompt = build_metadata_prompt(schema[\"account_info_fields\"])\n",
    "    account_info = call_ocr_llm(metadata_prompt, first_page_b64)[\"account_info\"]\n",
    "\n",
    "    # Stage 3 ‚Üí Transaction Extraction (all pages)\n",
    "    txn_prompt = build_transaction_prompt(schema[\"transaction_columns\"])\n",
    "    all_txns = []\n",
    "\n",
    "    for idx, page in enumerate(pages, start=1):\n",
    "        print(f\"Extracting transactions from page {idx}...\")\n",
    "        image_b64 = image_to_base64(page)\n",
    "        txns = call_ocr_llm(txn_prompt, image_b64)\n",
    "        all_txns.extend(txns[\"transactions\"])\n",
    "\n",
    "    # Combine results\n",
    "    return {\n",
    "        \"account_info\": account_info,\n",
    "        \"transactions\": all_txns,\n",
    "        \"schema\": schema\n",
    "    }\n",
    "\n",
    "# ---- USAGE ----\n",
    "if __name__ == \"__main__\":\n",
    "    result = process_bank_statement(\"sbi.pdf\")\n",
    "    print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74880f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import asyncio\n",
    "from PIL import Image\n",
    "import pdf2image\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# ---- CONFIG ----\n",
    "API_BASE = \"http://localhost:8000/v1\"\n",
    "MODEL_NAME = \"Qwen3-VL-30B-A3B-Instruct\"\n",
    "MAX_IMG_DIM = 1024\n",
    "\n",
    "client = AsyncOpenAI(api_key=\"EMPTY\", base_url=API_BASE)\n",
    "\n",
    "# ---- UTILITIES ----\n",
    "def pdf_to_images(pdf_path, dpi=200):\n",
    "    \"\"\"Convert all PDF pages to images.\"\"\"\n",
    "    return pdf2image.convert_from_path(pdf_path, dpi=dpi)\n",
    "\n",
    "def image_to_base64(image: Image.Image):\n",
    "    \"\"\"Convert PIL Image to base64 PNG.\"\"\"\n",
    "    max_dim = max(image.size)\n",
    "    if max_dim > MAX_IMG_DIM:\n",
    "        scale = MAX_IMG_DIM / max_dim\n",
    "        new_size = (int(image.size[0] * scale), int(image.size[1] * scale))\n",
    "        image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format='PNG')\n",
    "    return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "# ---- PROMPTS ----\n",
    "def schema_prompt():\n",
    "    return \"\"\"\n",
    "You are an intelligent data extraction assistant.\n",
    "You are given the first page of a bank statement that contains both account information and transaction table headers.\n",
    "\n",
    "Your goal:\n",
    "1. Identify and extract all account metadata fields (top section).\n",
    "2. Identify the column headers used for the transaction table on this page.\n",
    "\n",
    "Return JSON in this format:\n",
    "{\n",
    "  \"account_info_fields\": [\"...\"],\n",
    "  \"transaction_columns\": [\"...\"]\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Extract only visible labels (no values).\n",
    "- Preserve capitalization.\n",
    "- Prefer complete labels (e.g., ‚ÄúRef No./Cheque No‚Äù over ‚ÄúRef No.‚Äù).\n",
    "- Return valid JSON only.\n",
    "\"\"\"\n",
    "\n",
    "def build_metadata_prompt(account_info_fields):\n",
    "    json_fields = \", \".join([f'\"{f}\": \"\"' for f in account_info_fields])\n",
    "    return f\"\"\"\n",
    "Extract these account metadata fields from the image:\n",
    "{account_info_fields}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"account_info\": {{\n",
    "    {json_fields}\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Use the exact field names provided.\n",
    "- Use \"-\" if a value is missing.\n",
    "- Return valid JSON only.\n",
    "\"\"\"\n",
    "\n",
    "def build_transaction_prompt(transaction_columns):\n",
    "    json_fields = \", \".join([f'\"{c}\": \"\"' for c in transaction_columns])\n",
    "    return f\"\"\"\n",
    "Extract all transactions visible in this page using these headers:\n",
    "{transaction_columns}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"transactions\": [\n",
    "    {{\n",
    "      {json_fields}\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Map values based on column headers.\n",
    "- Use \"-\" for missing values.\n",
    "- Keep numeric precision to two decimals.\n",
    "- Return valid JSON only.\n",
    "\"\"\"\n",
    "\n",
    "# ---- ASYNC FUNCTIONS ----\n",
    "async def call_ocr_llm(prompt, image_base64):\n",
    "    \"\"\"Call OCR-capable LLM asynchronously.\"\"\"\n",
    "    response = await client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"}}\n",
    "            ]\n",
    "        }],\n",
    "        max_tokens=4096,\n",
    "        temperature=0.1,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "async def extract_transactions_for_page(page_idx, image, txn_prompt):\n",
    "    \"\"\"Extract transactions from one page (async).\"\"\"\n",
    "    image_b64 = image_to_base64(image)\n",
    "    print(f\"Extracting transactions from page {page_idx}...\")\n",
    "    try:\n",
    "        data = await call_ocr_llm(txn_prompt, image_b64)\n",
    "        return data.get(\"transactions\", [])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Page {page_idx} extraction failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# ---- MAIN PIPELINE ----\n",
    "async def process_bank_statement_async(pdf_path):\n",
    "    # Convert all PDF pages to images\n",
    "    pages = pdf_to_images(pdf_path)\n",
    "\n",
    "    # Stage 1: Schema discovery (sync ‚Äî only 1 page)\n",
    "    first_page_b64 = image_to_base64(pages[0])\n",
    "    schema = await call_ocr_llm(schema_prompt(), first_page_b64)\n",
    "\n",
    "    # Stage 2: Metadata extraction (first page)\n",
    "    metadata_prompt = build_metadata_prompt(schema[\"account_info_fields\"])\n",
    "    account_info = (await call_ocr_llm(metadata_prompt, first_page_b64))[\"account_info\"]\n",
    "\n",
    "    # Stage 3: Parallel transaction extraction\n",
    "    txn_prompt = build_transaction_prompt(schema[\"transaction_columns\"])\n",
    "\n",
    "    tasks = [\n",
    "        extract_transactions_for_page(i + 1, page, txn_prompt)\n",
    "        for i, page in enumerate(pages)\n",
    "    ]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    all_txns = [txn for page_txns in results for txn in page_txns]\n",
    "\n",
    "    return {\n",
    "        \"account_info\": account_info,\n",
    "        \"transactions\": all_txns,\n",
    "        \"schema\": schema\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067572e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "result = await process_bank_statement_async(\"icici.pdf\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5fe9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ALTERNATIVE: Simplified client without olmocr toolkit (less accurate)\n",
    "# This approach doesn't use document anchoring but still works for basic OCR\n",
    "\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import pdf2image\n",
    "import io\n",
    "import json\n",
    "\n",
    "def simple_pdf_to_olmocr(pdf_path, page_num=1):\n",
    "    \"\"\"\n",
    "    Simple PDF to OLMoCR without document anchoring\n",
    "    Note: This is less accurate than the full approach above\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert PDF page to image\n",
    "    pages = pdf2image.convert_from_path(pdf_path, first_page=page_num, last_page=page_num)\n",
    "    if not pages:\n",
    "        raise ValueError(\"Could not convert PDF page to image\")\n",
    "\n",
    "    # Resize image to 1024px longest dimension\n",
    "    image = pages[0]\n",
    "    max_dim = max(image.size)\n",
    "    if max_dim > 1024:\n",
    "        scale = 1024 / max_dim\n",
    "        new_size = (int(image.size[0] * scale), int(image.size[1] * scale))\n",
    "        image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Convert to base64\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format='PNG')\n",
    "    image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "    # Simple prompt (not as good as document anchoring)\n",
    "    prompt = \"\"\"\n",
    "Extract all information in json format.\n",
    "\"\"\"\n",
    "\n",
    "    # Send to vLLM\n",
    "    client = OpenAI(api_key=\"EMPTY\", base_url=\"http://localhost:8000/v1\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen3vl\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"}}\n",
    "            ]\n",
    "        }],\n",
    "        max_tokens=4096,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Usage\n",
    "result = simple_pdf_to_olmocr(\"icici.pdf\", 1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fdd0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mineru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01817b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mineru.api import paerse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6edb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mineru -p icici.pdf -b vlm-http-client -u http://localhost:8000 --start-page 1 --end-page 2 -o output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f759ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Replace with your actual service URL\n",
    "OCR_API_URL = \"http://localhost:8080/ocr\"\n",
    "\n",
    "# The image you want to send\n",
    "IMAGE_PATH = \"test.jpeg\"\n",
    "\n",
    "# Encode image to base64\n",
    "with open(IMAGE_PATH, \"rb\") as img_file:\n",
    "    image_b64 = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Prepare payload\n",
    "payload = {\n",
    "    \"prompt\": \"<image>\\nDocument to markdown\",\n",
    "    \"image_base64\": image_b64\n",
    "}\n",
    "\n",
    "# Send POST request\n",
    "response = requests.post(\n",
    "    OCR_API_URL,\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    data=json.dumps(payload),\n",
    "    timeout=300  # increase for large images\n",
    ")\n",
    "\n",
    "# Check response\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"\\n‚úÖ OCR Success!\")\n",
    "    print(\"Extracted Text:\\n\")\n",
    "    print(data.get(\"text_output\", \"\"))\n",
    "else:\n",
    "    print(\"\\n‚ùå Error:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ebddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import pdf2image\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# === CONFIG ===\n",
    "OCR_API_URL = \"http://localhost:8080/ocr\"\n",
    "PDF_PATH = \"test1.pdf\"\n",
    "PAGE_NUMBER = 1  # 1-based index\n",
    "\n",
    "\n",
    "def pdf_page_to_base64(pdf_path: str, page_num: int = 1) -> str:\n",
    "    \"\"\"\n",
    "    Converts a single PDF page to Base64 PNG image.\n",
    "    Uses pdf2image (Poppler) instead of fitz.\n",
    "    \"\"\"\n",
    "    # Convert the selected page to image\n",
    "    pages = pdf2image.convert_from_path(pdf_path, first_page=page_num, last_page=page_num)\n",
    "    if not pages:\n",
    "        raise ValueError(f\"Could not read page {page_num} from PDF\")\n",
    "\n",
    "    image = pages[0]\n",
    "\n",
    "    # Resize to 1024px longest side to avoid huge payloads\n",
    "    max_dim = max(image.size)\n",
    "    if max_dim > 1024:\n",
    "        scale = 1024 / max_dim\n",
    "        new_size = (int(image.size[0] * scale), int(image.size[1] * scale))\n",
    "        image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Convert to Base64 PNG\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format=\"PNG\")\n",
    "    image_b64 = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    return image_b64\n",
    "\n",
    "\n",
    "def send_to_ocr_api(image_b64: str):\n",
    "    \"\"\"\n",
    "    Sends the Base64-encoded image to the OCR API.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"prompt\": \"<image>\\n<|grounding|>Convert the document to markdown.\",\n",
    "        \"image_base64\": image_b64,\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        OCR_API_URL,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        data=json.dumps(payload),\n",
    "        timeout=300,\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(\"\\n‚úÖ OCR Success!\")\n",
    "        print(\"Extracted Text:\\n\")\n",
    "        print(data.get(\"text_output\", \"\"))\n",
    "        return data\n",
    "    else:\n",
    "        print(\"\\n‚ùå Error:\", response.status_code, response.text)\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_pdf_with_ocr(pdf_path: str, page_number: int):\n",
    "    \"\"\"\n",
    "    Extracts the given PDF page, converts it to Base64, and sends it to OCR.\n",
    "    \"\"\"\n",
    "    print(f\"üîπ Extracting page {page_number} from {pdf_path}...\")\n",
    "    base64_img = pdf_page_to_base64(pdf_path, page_number)\n",
    "    print(f\"‚úÖ Page {page_number} converted to Base64.\")\n",
    "\n",
    "    print(\"üîπ Sending to OCR API...\")\n",
    "    result = send_to_ocr_api(base64_img)\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_pdf_with_ocr(PDF_PATH, PAGE_NUMBER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260597ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install frontend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
